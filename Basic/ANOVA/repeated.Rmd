---
output:
  html_document:
    css: custom-blockquote.css
---

```{r setup&variables, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

# title: Repeated Measures ANOVA
# author: jonathan
# revised: 29/1/2020 

WEB <- c("https://bioceed.uib.no/dropfolder/bioSTATS/Rmd/Basic/ANOVA/repeated.html")
GIT <- c("https://github.com/jonathansoule/biostats/blob/master/Basic/ANOVA/repeated.Rmd")
library(nlme)
library(ggplot2)

```
**Repeated measures ANOVA** is a test that seems close to [one-way ANOVA](http://biostats.w.uib.no/one-way-anova/){target="_blank"} as it allows to check for differences between the means of three and more groups. The essential difference is that the groups are **dependent** (i.e. related). This means that the groups contain data or measurements from the same individuals. What differs in terms of design may be **when** measurements were taken (measurements were repeated in time: before, during, and after an experiment OR every day during a given time frame, OR etc) or **in which circumstances or conditions measurements** were performed (for example, measurements were done 3 times, each time following application of a new drug). 

In this test, the null hypothesis `H0` states that the means of all groups are equal.

Unlike [one-way ANOVA](http://biostats.w.uib.no/one-way-anova/){target="_blank"} where one fits a linear model with `lm()`, you may fit a **linear mixed effect model** with the function `lme()` that is found in the package `nlme`. However, we need to tell the function that some of the measurements are not replicates but that they concern the same individual. We will thus use the argument `random=~1|subjects` in `lme()`.

Letâs take an example where 5 rats are weighed 4 times with intervals of 4 weeks (week8 to 20). Here is the code for the dataframe:

```{r dataframe}
# response variable
rat.weight <- c(164,164,158,159,155,220,230,226,227,222,261,275,264,280,272,306,326,320,330,312)

# predictor variable
time.point <- as.factor(c(rep("week08",5), rep("week12",5), rep("week16",5), rep("week20",5)))

# individual ID
rat.ID <- as.factor(rep(c("rat1","rat2","rat3", "rat4", "rat5"),4))

# dataframe
my.dataframe <- data.frame(rat.ID,time.point,rat.weight)
```
<br/><br/>



Letâs visualize the data with a multiple line chart:
```{r plot, echo=FALSE}
ggplot(my.dataframe, aes(x = time.point, y = rat.weight, group = rat.ID, color = rat.ID)) +
  geom_line(size = 1.25) +
  geom_point(size = 2) +
  scale_color_viridis_d()
```
<br/><br/>

### Assumptions

Assumptions are:

+ each individual is represented in the form of a **measurement in each of the tested groups** (there cannot be any missing value),
+ **normality** of distribution (use the  [Shapiro-Wilk](https://biostats.w.uib.no/test-for-normality-shapiro-wilks-test/){target="_blank"}),
+ **sphericity**, which means that equality of variance is verified when comparing any two groups (all possible pairs of groups) in the experimental design (commonly checked via [Mauchly’s test](https://biostats.w.uib.no/test-for-sphericity-mauchly-test/){target="_blank"}), 
+ groups contain [**no outliers**](https://biostats.w.uib.no/finding-outliers/){target="_blank"}.

<br/><br/>

### Running the test

Since `lme()` is part of the package `nlme()`, you need to install and load it. Here is how to do it:

```{r nlme, eval=FALSE}
install.packages("nlme")
library(nlme)
```
<br/><br/>

The following code fits the linear mixed model. The syntax is `lme(response ~ predictor, data = my.dataframe)`, and we must not forget to add the argument `random=~1|rat.ID` to link the repeated measurements to the corresponding individuals in `rat.ID`:

```{r lme}
results.lme <- lme(rat.weight ~ time.point, random=~1|rat.ID, data=my.dataframe)
anova(results.lme)
```

The output shows a F-value close to 794 and a p-value under 0.0001. The null hypothesis can be rejected; there is a significant difference between the means of the groups. Unsurprisingly, this difference is due to the factor `time.point`, meaning that the rats grow with time (as expected in normal conditions). However, there is no indication of difference between individuals.

**But this does not tell us anything about the groups which means are significantly different.**

Indeed, this test tells you about an effect of the predictor variable, but does not tell you which groups are significantly different from others. For that, we will need *post hoc* tests such as [Tukey HSD](http://biostats.w.uib.no/post-hoc-tests-tukey-hsd/){target="_blank"}.

<br/><br/>

### Alternative

If you need an alternative test to the repeated measures ANOVA because, for example, you suspect violation of the assumption of normality of distribution, you may use a non-parametric test called [**Friedman rank sum test (or simply Friedman's test)**](http://biostats.w.uib.no/friedmans-test/){target="_blank"}.


<br/><br/>

***
<!-- UNCOMMENT TO ACTIVATE
Get the Rmarkdown file corresponding to this page on [GitHub](`r GIT`){target="_blank"}.
-->
