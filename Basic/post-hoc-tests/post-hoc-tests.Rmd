```{r setup&variables, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

# title: post-hoc tests
# author: jonathan
# revised: 31/1/2020 

WEB <- c("https://bioceed.uib.no/dropfolder/bioSTATS/Rmd/Basic/post-hoc tests/post-hoc-tests.html")
GIT <- c("https://github.com/jonathansoule/biostats/blob/master/Basic/post-hoc tests/post-hoc-tests.Rmd")
```

*Post hoc* tests are commonly used as a follow up to an F-test (such as [one-way-ANOVA](https://biostats.w.uib.no/one-way-anova/){target="_blank"}, [factorial ANOVA](https://biostats.w.uib.no/factorial-design/){target="_blank"}, …). These tests may be performed **only if** the F-test shows that there exists a significant difference between the means of the tested groups. **If not**, *post hoc* tests are not be used!

There exist many different tests, more or less conservative and adpated to your design, and finding the right test to use is often a challenge as one may be tempted to use a less conservative test to find lower p-value, with the increased risk to get type I errors (incorrect rejection of the null hypothesis stating that there is no difference between means).

This section of bioSTATS is not intended to tell you which test to choose in each situation; there are plenty of courses and online resources that do it already in a great way. Instead we show you the way to perform some of these common tests in R.

Here are a few useful functions in R that run *post hoc* tests. Let’s have a closer look at them:

+ [*post hoc* pairwise comparisons](https://biostats.w.uib.no/post-hoc-tests-pairwise-comparisons/){target="_blank"} with `pairwise.t.test()`,
+ [Tukey Honest Significant Difference](https://biostats.w.uib.no/post-hoc-tests-tukey-hsd/) (Tukey HSD) with `TukeyHSD()`.

<br/><br/>

***
<!-- UNCOMMENT TO ACTIVATE
Get the Rmarkdown file corresponding to this page on [GitHub](`r GIT`){target="_blank"}.
-->
